{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some IO operations in Numpy for loading and saving matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npy file usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 3) -0.3998810052871704 0.42214399576187134\n"
     ]
    }
   ],
   "source": [
    "# file_path = \"/home/zhanghm/Temp/cv-fighter/HDTF_preprocessed/WDA_SeanCasten_000/template_face.npy\"\n",
    "# file_path = \"/home/haimingzhang/Research/Github/FaceFormer/work_dir/train_face_3dmm_expression_mouth_mask_paper/test/lightning_logs/version_0/vis/train/WDA_BarackObama_000_000.npy\"\n",
    "\n",
    "# data = np.load(file_path)\n",
    "# print(data.shape, data.min(), data.max())\n",
    "\n",
    "# data2 = np.load(\"./data/id_coeff.npy\")\n",
    "# print(data2.shape)\n",
    "\n",
    "# diff = data - data2\n",
    "# print(diff.min(), diff.max())\n",
    "\n",
    "def load_binary_data():\n",
    "    file_path = \"/home/zhanghm/Research/V100/FaceFormer/data/big_mouth_mask.npy\"\n",
    "    data = np.load(file_path)\n",
    "    print(data.shape, data.min(), data.max())\n",
    "\n",
    "    print(np.count_nonzero(data))\n",
    "\n",
    "\n",
    "def load_dict_npy():\n",
    "    \"\"\"The npy file could be used to save dictionary data\n",
    "    \"\"\"\n",
    "    npy_fp = \"/home/zhanghm/Research/PU/ShapeFormer/experiments/vqdif/my_shapenet_res16/results/VisSparseRecon3D/computed/1.npy\"\n",
    "    data = np.load(npy_fp, allow_pickle=True)\n",
    "    content = data.item()\n",
    "\n",
    "    print(type(content), content.keys())\n",
    "    for key, value in content.items():\n",
    "        try:\n",
    "            print(key, value.shape)\n",
    "        except:\n",
    "            print(key, type(value))\n",
    "            print(value.keys())\n",
    "\n",
    "    print(content.keys(), content['logits'].shape, content['quant_ind'].shape)\n",
    "    print(np.unique(content['quant_ind']))\n",
    "\n",
    "\n",
    "npy_fp = \"/data/zhanghm/Datasets/ShapeNet/PointTr_Dataset/ShapeNet55/shapenet_pc/04256520-c3e86ca4f6ca077459d0a47cd36512.npy\"\n",
    "Xct = np.load(npy_fp)\n",
    "print(Xct.shape, Xct.min(), Xct.max())\n",
    "np.savetxt(\"Xbd2.xyz\", Xct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(402, 257) (402, 257)\n",
      "-0.2383115 0.2779872\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr1 = np.load(\"/home/zhanghm/Research/StyleGAN/Deep3DFaceRecon_pytorch/pred_coeffs_new.npy\")\n",
    "arr2 = np.load(\"/home/zhanghm/Research/StyleGAN/Deep3DFaceRecon_pytorch/pred_coeffs.npy\")\n",
    "print(arr1.shape, arr2.shape)\n",
    "\n",
    "diff = arr1 - arr2\n",
    "print(diff.min(), diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npz file usages\n",
    "https://vimsky.com/examples/usage/python-numpy.savez.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'point', 'sample_near']\n",
      "(10, 95400, 3) (10, 95400, 3) (95400, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_npz():\n",
    "    npz_file_path = \"./data/obama2.npz\"\n",
    "    netparams = np.load(open(npz_file_path, 'rb'))\n",
    "\n",
    "    print(netparams.files)  ## Get the dictionary keys\n",
    "\n",
    "    content = netparams['face']\n",
    "    print(type(netparams), content.shape, np.min(content), np.max(content))\n",
    "\n",
    "    ## Another npz file\n",
    "    real_params = \"/home/haimingzhang/Research/Face/FACIAL/gangqiang_2_preprocess/deep3dface.npz\"\n",
    "    realparams = np.load(open(real_params, 'rb'))['face']\n",
    "    print(realparams.shape)\n",
    "\n",
    "\n",
    "def load_npz2():\n",
    "    npz_fp = \"/home/zhanghm/Research/PU/ShapeFormer/experiments/my_demo_vqdif/eval/0.npz\"\n",
    "    content = np.load(open(npz_fp, \"rb\"))\n",
    "    print(content.files)\n",
    "\n",
    "    eval_pc = content['eval_pc']\n",
    "    print(eval_pc.shape)\n",
    "    np.savetxt(\"eval_pc.xyz\", eval_pc)\n",
    "\n",
    "\n",
    "def load_npz3():\n",
    "    npz_fp = \"/home/zhanghm/Research/PU/Github/NeuralPull-Pytorch/data/gargoyle.npz\"\n",
    "    load_data = np.load(npz_fp)\n",
    "    print(load_data.files)\n",
    "\n",
    "    print(load_data['sample_near'].shape, load_data['sample'].shape, load_data['point'].shape)\n",
    "    np.savetxt(\"0_sample_near.xyz\", load_data['sample_near'][0])\n",
    "    np.savetxt(\"0_sample.xyz\", load_data['sample'][0])\n",
    "    np.savetxt(\"0_point.xyz\", load_data['point'])\n",
    "\n",
    "\n",
    "def write_npz():\n",
    "    face_params = np.zeros((10, 64), np.float)\n",
    "    np.savez(\"./data/example.npz\", face=face_params)\n",
    "    \n",
    "load_npz3()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "txt_fp = \"/home/zhanghm/Research/PU/VQPC/PU-Net/data/test_data/our_collected_data/MC_5k/camel.xyz\"\n",
    "\n",
    "input = np.loadtxt(txt_fp)\n",
    "print(input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine different parameters from two persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1419, 257) -3.4403297901153564 3.5975096225738525\n"
     ]
    }
   ],
   "source": [
    "another_deep3dface_npz = \"/home/haimingzhang/Research/Face/FACIAL/video_preprocessed/id00001/gangqiang_3/deep3dface.npz\"\n",
    "\n",
    "netparams = np.load(open(another_deep3dface_npz, 'rb'))['face']\n",
    "\n",
    "print(type(netparams), netparams.shape, np.min(netparams), np.max(netparams))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 15069) -0.18839313089847565 0.13654573261737823\n"
     ]
    }
   ],
   "source": [
    "file_path = \"/home/haimingzhang/Research/Face/voca/training_data/init_expression_basis.npy\"\n",
    "file_path = \"/home/zhanghm/Research/Github/FaceFormer/vocaset/vertices_npy/FaceTalk_170725_00137_TA_sentence01.npy\"\n",
    "\n",
    "expression_basis = np.load(file_path)\n",
    "print(expression_basis.shape, np.min(expression_basis), np.max(expression_basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "0.0019309520721435547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "time1 = time.time()\n",
    "mask = np.load(\"/home/haimingzhang/Research/Programming/cv-fighter/face_fighter/3DMM/mask.npy\")\n",
    "# mask = cv2.imread(\"/home/haimingzhang/Research/Programming/cv-fighter/face_fighter/3DMM/mask.png\")\n",
    "# mask = np.load(open(\"/home/haimingzhang/Research/Programming/cv-fighter/face_fighter/3DMM/mask.npz\", \"rb\"))['mask']\n",
    "print(mask.dtype)\n",
    "time2 = time.time()\n",
    "print(time2 - time1)\n",
    "\n",
    "def get_contour(im):\n",
    "    contours, hierarchy = cv2.findContours(im.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    out = np.zeros_like(im)\n",
    "    out = cv2.fillPoly(out, contours, 255)\n",
    "\n",
    "    return out\n",
    "\n",
    "mask2 = get_contour(mask)\n",
    "cv2.imwrite(\"mask2.png\", mask2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38-torch100-cu11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56d0891f27fe2db3830dc2a05bc70f05135b0c30ed7c190a150d1aca2da3af60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
