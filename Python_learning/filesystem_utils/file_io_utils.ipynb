{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn how to load, read and write different commonly used file formats in Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sth\n",
    "import os\n",
    "from os.path import dirname, join, basename, isfile, isdir\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain text format (e.g `.txt`) IO processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is zhanghaiming. <class '_io.TextIOWrapper'>\n",
      "['210905_368_4', '210905_590_4', '210905_590_5', '210905_598_4', '210905_598_5', '210905_647_5', '210905_647_6', '210906_28_6', '210903_8_4', '210903_20_6', '210903_20_7', '210903_20_8', '210903_49_4', '210903_49_6', '210903_49_7', '210903_49_8', '210903_50_4', '210903_50_7', '210903_51_5', '210903_51_6', '210903_51_7', '210903_197_0', '210903_198_0', '210904_21_1', '210904_22_3', '210904_22_4', '210904_22_6', '210904_22_7', '210904_22_20', '210904_28_0', '210904_28_2', '210904_28_3', '210904_28_4', '210904_28_5', '210904_28_7', '210904_244_4', '210904_244_5', '210904_244_6', '210904_244_7', '210904_248_0', '210904_248_1', '210904_248_2', '210904_248_3', '210904_248_4', '210904_248_5', '210904_397_4', '210904_397_12', '210904_402_3', '210904_402_8', '210904_419_5', '210904_628_0', '210904_628_1', '210904_628_3', '210904_628_5', '210904_1168_6', '210904_1168_7', '210904_1168_8', '210904_1210_0', '210904_1214_1', '210904_1223_8', '210904_1230_8', '210904_1235_8', '210905_64_3', '210905_64_5', '210905_123_5', '210905_323_6', '210905_323_7', '210905_368_2', '210905_368_3'] 69\n",
      "['6300370419826092098/00001 6300370419826092098/00001 95 3.84', '6300370419826092098/00002 6300370419826092098/00002 58 2.368', '6300370419826092098/00003 6300370419826092098/00003 39 1.6', '6300370419826092098/00004 6300370419826092098/00004 32 1.28', '6300370419826092098/00006 6300370419826092098/00006 58 2.368', '6300370419826092098/00007 6300370419826092098/00007 138 5.568', '6300370419826092098/00010 6300370419826092098/00010 147 5.888', '6300370419826092098/00012 6300370419826092098/00012 26 1.088', '6300370419826092098/00013 6300370419826092098/00013 112 4.48', '6300370419826092098/00014 6300370419826092098/00014 33 1.344'] 1082\n"
     ]
    }
   ],
   "source": [
    "### 读txt文件操作\n",
    "filename = \"../data/example.txt\"\n",
    "txt = open(filename)\n",
    "text_str = txt.read()\n",
    "print(text_str, type(txt)) #即打印所有文件内容\n",
    "txt.close()\n",
    "\n",
    "### 写txt文件操作\n",
    "filename = \"../data/example_write.txt\"\n",
    "txt = open(filename,'w')\n",
    "txt.write(\"hello world!\")\n",
    "txt.close()\n",
    "\n",
    "def read2list(file_path):\n",
    "    \"\"\"Read content in a plain text file line by line\n",
    "    \"\"\"\n",
    "    fp = open(file_path)\n",
    "    content = [line.strip() for line in fp]\n",
    "    return content\n",
    "\n",
    "def read2list2(file_path):\n",
    "    lines = open(file_path).read().splitlines()\n",
    "    return lines\n",
    "\n",
    "data = read2list(\"../data/bad_data_name.txt\")\n",
    "print(data, len(data))\n",
    "\n",
    "lines = read2list2(\"/home/haimingzhang/Research/Face/Wav2Lip/filelists/sync_pairs.txt\")\n",
    "print(lines[:10], len(lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用numpy读txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1098,) ['test/7974/7974-cut-51' 'test/7974/7974-cut-38' 'test/7974/7974-cut-73']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_text_file = \"test.txt\"\n",
    "data_input = np.loadtxt(input_text_file, delimiter='\\n', dtype=np.str)\n",
    "print(data_input.shape, data_input[:3])\n",
    "\n",
    "\n",
    "def read_txt_to_numpy(file_path):\n",
    "    a = np.loadtxt(file_path)\n",
    "    print(a.shape, a.dtype)\n",
    "\n",
    "def read_kitti_oxts(dataset_root, sequence_num):\n",
    "    \"\"\"\n",
    "    read txt file line by line to a dictionary\n",
    "    \"\"\"\n",
    "    oxts_file = os.path.join(dataset_root, 'oxts/{0:04d}.txt'.format(int(sequence_num)))\n",
    "\n",
    "    with open(oxts_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    print(len(lines))\n",
    "    oxts_dict = {}\n",
    "    for i, line in enumerate(lines):\n",
    "        oxt = line.strip().split(' ')\n",
    "        oxts_dict[i] = oxt\n",
    "    return oxts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json format file IO processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load json file content to dictionary\n",
    "basedir = \"./data/\"\n",
    "splits = ['train', 'val', 'test']\n",
    "metas = {}\n",
    "for s in splits:\n",
    "    with open(os.path.join(basedir, 'transforms_{}.json'.format(s)), 'r') as fp:\n",
    "        metas[s] = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def validate_data(vid_file):\n",
    "    video_stream = cv2.VideoCapture(vid_file)\n",
    "    FRAME_COUNT = int(video_stream.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    vidname = os.path.basename(vid_file).split('.')[0]\n",
    "    dirname = vid_file.split('/')[-2]\n",
    "\n",
    "    fulldir = os.path.join(\"/data/zhanghm/speech_chinese_preprocessed\", dirname, vidname)\n",
    "    face_images_list = [file.path for file in os.scandir(fulldir)]\n",
    "    face_num = len(face_images_list)\n",
    "\n",
    "    if face_num != FRAME_COUNT:\n",
    "        print(f\"Error in {vid_file} video length:{FRAME_COUNT} face_num:{face_num}\")\n",
    "\n",
    "\n",
    "validate_data(\"/data/zhanghm/speech_chinese/210903/210903_101_17.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `.mat` Matlab type matrix file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27507985\n",
      "__header__ b'MATLAB 5.0 MAT-file Platform: posix, Created on: Tue Jan  4 13:43:13 2022'\n",
      "__version__ 1.0\n",
      "__globals__ []\n",
      "cropped_img (224, 224, 3)\n",
      "recon_img (224, 224, 4)\n",
      "coeff (1, 257)\n",
      "face_shape (35709, 3)\n",
      "face_texture (35709, 3)\n",
      "face_color (35709, 3)\n",
      "lm_68p (68, 2)\n",
      "lm_5p (5, 2)\n",
      "-4.406795 4.1808734\n",
      "197 181\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "input_data = \"/home/haimingzhang/Research/Face/Deep3DFaceRecon_pytorch/checkpoints/face_recon_feat0.2_augment-20210829T083504Z-001/results/gangqiang-2-30fps/epoch_20_000000/000000.mat\"\n",
    "input_data = \"../data/1.mat\"\n",
    "\n",
    "input_data = \"/home/haimingzhang/Research/Face/Deep3DFaceReconstruction/FACIAL/gangqiang_video_preprocess_old/gangqiang-2_deep3Dface/000000.mat\"\n",
    "face_params = loadmat(input_data)\n",
    "\n",
    "input_data = \"/home/haimingzhang/Research/Face/Deep3DFaceReconstruction/FACIAL/gangqiang_video_preprocess/gangqiang_deep3Dface/000000.mat\"\n",
    "face_params2 = loadmat(input_data)\n",
    "\n",
    "diff = face_params2['coeff'] - face_params['coeff']\n",
    "print(np.max(diff))\n",
    "\n",
    "for key, value in face_params.items():\n",
    "    if not key.endswith(\"__\"):\n",
    "        print(key, value.shape)\n",
    "    else:\n",
    "        print(key, value)\n",
    "\n",
    "coeff = face_params[\"coeff\"]\n",
    "print(np.min(coeff), np.max(coeff))\n",
    "\n",
    "max_index, min_index = np.argmax(coeff), np.argmin(coeff)\n",
    "print(max_index, min_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 257) -3.0490904 3.5985098\n",
      "0.9397843\n",
      "0.22263241 -0.23398256\n",
      "207 208\n"
     ]
    }
   ],
   "source": [
    "def get_coeff_vector(mat_path):\n",
    "    \"\"\"Get coefficient vector from Deep3DFace_Pytorch results\n",
    "\n",
    "    Args:\n",
    "        mat_path ([type]): [description]\n",
    "\n",
    "    Returns:\n",
    "        [type]: 1x257\n",
    "    \"\"\"\n",
    "    keys_list = ['id', 'exp', 'tex', 'angle', 'gamma', 'trans']\n",
    "\n",
    "    face_params = loadmat(mat_path)\n",
    "\n",
    "    coeff_list = []\n",
    "    for key in keys_list:\n",
    "        coeff_list.append(face_params[key])\n",
    "    \n",
    "    coeff_res = np.concatenate(coeff_list, axis=1)\n",
    "    return coeff_res\n",
    "\n",
    "\n",
    "input_data = \"/home/haimingzhang/Research/Face/Deep3DFaceRecon_pytorch/checkpoints/face_recon_feat0.2_augment-20210829T083504Z-001/results/gangqiang-2-30fps/epoch_20_000000/000000.mat\"\n",
    "coeff = get_coeff_vector(input_data)\n",
    "print(coeff.shape, np.min(coeff), np.max(coeff))\n",
    "\n",
    "input_data = \"/home/haimingzhang/Research/Face/Deep3DFaceReconstruction/FACIAL/gangqiang_video_preprocess_old/gangqiang-2_deep3Dface/000000.mat\"\n",
    "face_params = loadmat(input_data)\n",
    "\n",
    "diff = face_params['coeff'][:, :80] - coeff[:, :80]\n",
    "print(np.max(diff))\n",
    "\n",
    "input_data = \"/home/haimingzhang/Research/Face/Deep3DFaceRecon_pytorch/checkpoints/face_recon_feat0.2_augment-20210829T083504Z-001/results/gangqiang-2-512x512/epoch_20_000000/000000.mat\"\n",
    "coeff2 = get_coeff_vector(input_data)\n",
    "\n",
    "diff = coeff2 - coeff\n",
    "print(np.max(diff), np.min(diff))\n",
    "\n",
    "max_index, min_index = np.argmax(diff), np.argmin(diff)\n",
    "print(max_index, min_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify existing file according some conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dataset format:\n",
    "TAudio id08885/cIqVKLOtfyk/00251 id08885/cIqVKLOtfyk/00251 5.31 0 5.31 0 0 146975\n",
    "TFAudio id04335/WEed3nlDs80/00045 id04346/2rc759vfCb0/00003 5.88 0 3.58 3.58 5.88 146977\n",
    "TSilence silence/4O2JKS94g3Y/20463 silence/4O2JKS94g3Y/20463 2.46 1.4 2.46 0 1.4 146979\n",
    "\"\"\"\n",
    "def remove_specified_lines(src_file, remove_list=[]):\n",
    "    lines = open(src_file).read().splitlines()\n",
    "\n",
    "    lines_new = []\n",
    "    for line in lines:\n",
    "        data = line.split()\n",
    "        if data[0] in remove_list:\n",
    "            continue\n",
    "        lines_new.append(line)\n",
    "    \n",
    "    lines_new_str = \"\\n\".join(lines_new)\n",
    "    with open(\"test_new.txt\", \"w\") as fp:\n",
    "        fp.write(lines_new_str)\n",
    "\n",
    "remove_specified_lines(\"./lists/lists_out/test.txt\", remove_list=[\"TSilence\", \"TFAudio\", \"FSilence\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a905e65f9d17f2b99942353106a9a9bb4e3ae6eb3c5eda96a0f871aef2e2b8d2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('face_python36': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
