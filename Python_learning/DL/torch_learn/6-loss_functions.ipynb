{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play with different Loss Functions in Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Resources\n",
    "[all-pytorch-loss-function](https://analyticsindiamag.com/all-pytorch-loss-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pred = torch.randn(4, 200, 200, 16, 18)\n",
    "target = torch.randn(4, 200, 200, 16, 18)\n",
    "\n",
    "pred = torch.randn(4, 18)\n",
    "target = torch.randn(4, 18)\n",
    "T = 10\n",
    "\n",
    "\n",
    "kd_loss = F.kl_div(\n",
    "        F.log_softmax(pred / T, dim=1), target, reduction='none').mean(1) * (\n",
    "            T * T)\n",
    "print(kd_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([2, 36])\n",
      "tensor(-0.0144)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmdet.models.losses import KnowledgeDistillationKLDivLoss\n",
    "\n",
    "kl_loss = KnowledgeDistillationKLDivLoss()\n",
    "\n",
    "pred = torch.randn(4, 18)\n",
    "target = torch.randn(4, 18)\n",
    "weight = torch.randn(4)\n",
    "print(weight.shape)\n",
    "dd = pred.reshape(2, -1)\n",
    "print(dd.shape)\n",
    "\n",
    "loss = kl_loss(pred, target, weight)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc_loss_with_different_methods\n",
      "tensor([[[16., 14.],\n",
      "         [12., 10.],\n",
      "         [ 8.,  6.],\n",
      "         [ 4.,  2.]],\n",
      "\n",
      "        [[ 0.,  2.],\n",
      "         [ 4.,  6.],\n",
      "         [ 8., 10.],\n",
      "         [12., 14.]]]) torch.Size([2, 4, 2])\n",
      "tensor(8.)\n",
      "tensor(8.)\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "### https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html\n",
    "def cal_loss(input, target):\n",
    "    \"\"\"\n",
    "    MAE计算细节\n",
    "    \"\"\"\n",
    "    print(target - input)\n",
    "    print(torch.abs(target - input))\n",
    "    ### Calculate the absolute\n",
    "    diff = input - target\n",
    "    abs_diff = torch.abs(diff)\n",
    "    mae = torch.mean(abs_diff)\n",
    "    print(mae)\n",
    "\n",
    "\n",
    "def calc_loss_with_different_methods(pred, tgt):\n",
    "    print(\"calc_loss_with_different_methods\")\n",
    "    ## Method 1\n",
    "    l1_loss = nn.L1Loss(reduction='none')\n",
    "    output = l1_loss(pred, tgt)\n",
    "    print(output, output.shape)\n",
    "    \n",
    "    output = torch.mean(output) # the same with nn.L1Loss(reduction='mean')\n",
    "    print(output)\n",
    "\n",
    "    ## Method 2\n",
    "    l1_loss = nn.L1Loss()\n",
    "    output = l1_loss(pred, tgt)\n",
    "    print(output)\n",
    "\n",
    "    ## Method 3\n",
    "    output = F.l1_loss(pred, tgt)\n",
    "    print(output)\n",
    "\n",
    "\n",
    "pred = torch.arange(16).reshape(2, 4, 2).to(torch.float32)\n",
    "target = torch.arange(16, 0, step=-1).reshape(2, 4, 2).to(torch.float32)\n",
    "\n",
    "calc_loss_with_different_methods(pred, target)\n",
    "\n",
    "\n",
    "# mae_loss = nn.L1Loss(reduction='mean')\n",
    "# input = torch.randn(3, 5)\n",
    "# target = torch.randn(3, 5)\n",
    "# target = torch.tensor([[1,2,3,4,5],[1,2,3,4,5], [1,2,3,4,5.0]])\n",
    "# target = torch.tensor([[1,2,3,4,5.0]])\n",
    "\n",
    "# print(input, target)\n",
    "# cal_loss(input, target)\n",
    "\n",
    "# output = mae_loss(input, target)\n",
    "# print(output, output.shape)\n",
    "\n",
    "# target = torch.tensor([[1,2,3,4,5],[1,2,3,4,5], [1,2,3,4,5.0]])\n",
    "# output = mae_loss(input, target)\n",
    "# print(output, output.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2222)\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8., 11.]])\n",
      "tensor([[1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor(1.2222)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def pixel_wise_loss(pred, target, mask=None, weight=1.0):\n",
    "    l1_dist = F.l1_loss(pred, target, reduction=\"none\")\n",
    "\n",
    "    if mask is None:\n",
    "        return torch.mean(l1_dist)\n",
    "    \n",
    "    loss1 = weight * l1_dist * mask\n",
    "    loss2 = l1_dist * (1 - mask)\n",
    "    \n",
    "    loss = torch.mean(loss1 + loss2)\n",
    "    return loss\n",
    "\n",
    "pred = torch.arange(0, 9).reshape(3, 3).to(torch.float32)\n",
    "\n",
    "# target = torch.arange(9, 0, -1).reshape(3, 3).to(torch.float32)\n",
    "target = torch.arange(1, 10).reshape(3, 3).to(torch.float32)\n",
    "# target[0, 0] += 2\n",
    "\n",
    "target[2, 2] += 2\n",
    "\n",
    "\n",
    "print(pred)\n",
    "print(target)\n",
    "\n",
    "mask = torch.zeros_like(target)\n",
    "mask[:2, :2] = 1.\n",
    "print(mask)\n",
    "\n",
    "loss = pixel_wise_loss(pred, target)\n",
    "# loss = pixel_wise_loss(pred, target, mask=mask, weight=2.0)\n",
    "\n",
    "print(loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth L1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "mse_criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "pred = torch.tensor([[0, 2, 2, 4]], dtype=torch.float32)\n",
    "target = torch.tensor([[2, 3, 4, 5]], dtype=torch.float32)\n",
    "\n",
    "mse_loss = mse_criterion(pred, target)\n",
    "print(mse_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Pytorch实现\n",
    "input = torch.randn(3, 4, requires_grad=True)\n",
    "target = torch.randn(3, 4)\n",
    "mse_loss = nn.MSELoss()\n",
    "output = mse_loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print('input -: ', input)\n",
    "print('target -: ', target)\n",
    "print('output -: ', output)\n",
    "\n",
    "pred = torch.arange(0, 9).reshape(3, 3).to(torch.float32) / 9.0\n",
    "# pred[0, 0] = 0.5\n",
    "# pred[2, 2] = 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "target = torch.arange(9, 0, -1).reshape(3, 3).to(torch.float32) / 9.0\n",
    "print(target)\n",
    "\n",
    "pred[2] = target[2]\n",
    "# pred[2, :2] = target[2, :2]\n",
    "print(pred)\n",
    "\n",
    "class WeightedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        weight = -torch.log(1 - target + 1e-5)\n",
    "        weighted_diff = torch.multiply((pred - target), weight)\n",
    "        \n",
    "        return torch.sum(torch.pow(weighted_diff, 2))\n",
    "\n",
    "mse_loss = WeightedLoss()\n",
    "output = mse_loss(pred, target)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy(nn.BCELoss)\n",
    "[https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)\n",
    "\n",
    "[https://gombru.github.io/2018/05/23/cross_entropy_loss/](https://gombru.github.io/2018/05/23/cross_entropy_loss/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE error is: 0.43800269247783435\n"
     ]
    }
   ],
   "source": [
    "### Python实现\n",
    "y_pred = np.array([0.1580, 0.4137, 0.2285])\n",
    "y_true = np.array([0.0, 1.0, 0.0]) #2 labels: (0,1)\n",
    "def BCE(y_pred, y_true):\n",
    "    total_bce_loss = np.sum(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
    "    # Getting the mean BCE loss\n",
    "    num_of_samples = y_pred.shape[0]\n",
    "    mean_bce_loss = total_bce_loss / num_of_samples\n",
    "    return mean_bce_loss\n",
    "bce_value = BCE(y_pred, y_true)\n",
    "print (\"BCE error is: \" + str(bce_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n",
      "tensor(0.4380, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## Using Pytorch implementation\n",
    "bce_loss = torch.nn.BCELoss()\n",
    "sigmoid = torch.nn.Sigmoid() # Ensuring inputs are between 0 and 1\n",
    "input = torch.tensor(y_pred)\n",
    "target = torch.tensor(y_true)\n",
    "print(input.shape, target.shape)\n",
    "output = bce_loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCEWithLogitsLoss(nn.BCEWithLogitsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11.1664],\n",
      "        [81.5843],\n",
      "        [26.2562],\n",
      "        [48.3878],\n",
      "        [67.6504],\n",
      "        [75.3911],\n",
      "        [26.2691],\n",
      "        [ 4.2840],\n",
      "        [20.8029],\n",
      "        [11.8037],\n",
      "        [12.1695],\n",
      "        [73.5599],\n",
      "        [71.1765],\n",
      "        [78.7581],\n",
      "        [41.8305],\n",
      "        [90.1415]])\n",
      "tensor([[1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [0.9864],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000],\n",
      "        [1.0000]])\n",
      "torch.Size([16, 1])\n",
      "tensor(0.6931)\n",
      "tensor(27.6075)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def example1():\n",
    "    model = nn.Linear(10, 1)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    x = torch.randn(16, 10)\n",
    "    y = torch.empty(16).random_(2)  # (16, )\n",
    "    print(y, y.shape)\n",
    "\n",
    "    out = model(x)  # (16, 1)\n",
    "    out = out.squeeze(dim=-1)  # (16, )\n",
    "\n",
    "    print(out)\n",
    "\n",
    "    loss = criterion(y, y)\n",
    "    print(loss)\n",
    "\n",
    "def example2():\n",
    "    torch.manual_seed(100)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion2 = nn.BCELoss()\n",
    "\n",
    "    pred = torch.rand(16,1) * 100\n",
    "    print(pred)\n",
    "\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    print(sigmoid(pred))\n",
    "\n",
    "    target = torch.zeros_like(pred)\n",
    "    print(target.shape)\n",
    "\n",
    "    loss = criterion(target, pred)\n",
    "    print(loss)\n",
    "\n",
    "    print(criterion2(target, sigmoid(pred)))\n",
    "\n",
    "example2()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntroypLoss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.models.losses import CrossEntropyLoss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosineEmbeddingLoss\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n",
      "tensor(-1.1176e-08)\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CosineEmbeddingLoss()\n",
    "\n",
    "v1 = torch.randn((16, 64))\n",
    "v2 = torch.randn((16, 64))\n",
    "v2 = v1 * 0.6\n",
    "\n",
    "target = torch.ones((v1.shape[0]))\n",
    "print(target.shape)\n",
    "\n",
    "loss = criterion(v1, v2, target)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/haimingzhang/miniconda3/envs/GAN/lib/python3.6/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /home/haimingzhang/miniconda3/envs/GAN/lib/python3.6/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "torch.Size([])\n",
      "tensor(0.4945, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import lpips\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg') # closer to \"traditional\" perceptual loss, when used for optimization\n",
    "\n",
    "import torch\n",
    "img0 = torch.zeros(1,3,64,64) # image should be RGB, IMPORTANT: normalized to [-1,1]\n",
    "img1 = torch.ones(1,3,64,64)\n",
    "d = torch.mean(loss_fn_vgg(img0, img1))\n",
    "print(d.shape)\n",
    "print(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Variation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0004)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "\n",
    "def total_variation_loss(img):\n",
    "    bs_img, c_img, h_img, w_img = img.size()\n",
    "    tv_h = torch.pow(img[:,:,1:,:]-img[:,:,:-1,:], 2).sum()\n",
    "    tv_w = torch.pow(img[:,:,:,1:]-img[:,:,:,:-1], 2).sum()\n",
    "    return (tv_h + tv_w) / (bs_img*c_img*h_img*w_img)\n",
    "\n",
    "img = cv2.imread(\"/home/zhanghm/Research/V100/programming-learning-examples/Python_learning/data/obama.jpg\")\n",
    "img_pred = torch.rand(1,3,64,64)\n",
    "img_pred = torch.FloatTensor(img)[None] / 255\n",
    "img_pred = img_pred.permute(0,3,1,2)\n",
    "\n",
    "loss = total_variation_loss(img_pred)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('py36-torch100-cu11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a061662cd1728e1a413eb44216c5a5b0f5a1d783e658cf909fe334fc01234e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
